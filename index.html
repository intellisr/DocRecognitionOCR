<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Tensorflow classifier</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js" type="text/javascript"></script>
    <script src="js/azure-storage-blob.js" charset="utf-8"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
</head>

<body>
    <h2>Tensorflow classifier</h2>
    <p id="status">OpenCV.js is loading...</p>
    <div>
        <div class="inputoutput" style="width: 50%;">
            <img id="imageSrc" alt="No Image" height="400px" width="auto" />
            <div class="caption">imageSrc
                <input type="file" id="canvasInput" name="file" />
            </div>
            <h1 id="p2">Checking Clear output....</h1>
            <h1 id="p1">loading..</h1>
        </div>
        <div id="ocr" style="width: 40%;margin-left: 10%;">

        </div>
        <div class="inputoutput">
            <canvas id="canvasOutput"></canvas>
        </div>
        
    </div>
    <script type="text/javascript">
        const accountName = "intellisr2storage";
        const sasString = "sp=racwdl&st=2021-10-06T16:37:03Z&se=2021-12-01T00:37:03Z&sv=2020-08-04&sr=c&sig=09RMOFFBuuMXlZc24YRKwZtk54z4pY9o8%2BkitYrFZjw%3D";
        const containerName = "images";
        const containerURL = new azblob.ContainerURL(
            `https://${accountName}.blob.core.windows.net/${containerName}?${sasString}`,
        azblob.StorageURL.newPipeline(new azblob.AnonymousCredential));

        const MODEL_URL="https://cdn.glitch.me/fce7d000-fcaa-4574-b6b6-9d66062f49d1%2Fmodel.json?v=1633416801718";

        let imgElement = document.getElementById('imageSrc');
        let inputElement = document.getElementById('canvasInput');
        

        inputElement.addEventListener('change', (e) => {
            imgElement.src = URL.createObjectURL(e.target.files[0]);
        }, false);

        imgElement.onload = function () {
            document.getElementById('p1').innerHTML = 'Loading...';
            $("#ocr" ).empty();
            let src = cv.imread(imgElement);
            let dst = new cv.Mat();
            let std = new cv.Mat();
            let menO = new cv.Mat();
            cv.cvtColor(src, src, cv.COLOR_RGB2GRAY, 0);

            cv.Laplacian(src, dst, cv.CV_64F, 1, 1, 0, cv.BORDER_DEFAULT);
            cv.meanStdDev(dst, menO, std);
            console.log("Blur",std.data64F[0]);
            if(std.data64F[0] > 8){
                document.getElementById("p2").innerHTML = "Not blur";
                predict(imgElement);
                //faceDetect();
                //getContour();
                
            }else{
                document.getElementById("p2").innerHTML = "blur";
            }
            src.delete(); dst.delete(); 

        };

        function onOpenCvReady() {
            document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
        }


        const predict = async (img) => {
            
            // Load the model from the CDN.
            const model = await tf.loadGraphModel(MODEL_URL);

            let image = preprocessImage(img, "mobilenet")

            let predictions = await model.predict(image).data();

            let result=getPredictResult(predictions);

            let classImg=result[0]['className'];
            // console.log()
            if(result[0]['probability'] > 1.5 ){
                document.getElementById('p1').innerHTML = 'Type: '+classImg; 
            }else{
                document.getElementById('p1').innerHTML = '(not sure)Type: '+classImg;
            }

            uploadFiles(classImg);
                 
        }

        const preprocessImage = (image, modelName) => {

                // resize the input image to mobilenet's target size of (224, 224)
                let tensor = tf.browser.fromPixels(image)
                .resizeNearestNeighbor([224, 224])
                .toFloat();

                // if model is not available, send the tensor with expanded dimensions
                if (modelName === undefined) {
                    return tensor.expandDims();
                } 

                // if model is mobilenet, feature scale tensor image to range [-1, 1]
                else if (modelName === "mobilenet") {
                let offset = tf.scalar(127.5);
                return tensor.sub(offset)
                    .div(offset)
                    .expandDims();
                } 

                // else throw an error
                else {
                    alert("Unknown model name..")
                }
        }

        const getPredictResult = (predictions) => {
            const CLASSES = ['Driving License Front','Driving License Front Old', 'Driving License Back Old', 'Driving License Back', 'New NIC Front', 'New NIC Back', 'Old NIC Front', 'Old NIC Back', 'Passport'];
            // get the model's prediction results
            let results = Array.from(predictions)
                    .map(function (p, i) {
                    return {
                        probability: p,
                        className: CLASSES[i]
                    };
                    }).sort(function (a, b) {
                    return b.probability - a.probability;
                    }).slice(0, 5);
            
            return results;        
        }

        const getContour = () =>{
            let src = cv.imread(imgElement);
            const canvasOutput = document.querySelector('#canvasOutput');
            let gray = new cv.Mat();
            let edged = new cv.Mat();
            let contours = new cv.MatVector();
            let hierarchy = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGB2GRAY, 0);
            cv.Canny(gray, edged, 30, 80, 3, true);
            cv.findContours(edged, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
            var cntareas=[];
            for (let i = 0; i < contours.size(); i++) {
                cntareas.push(cv.contourArea(contours.get(i)));
            }
            var indexOfMaxValue = cntareas.reduce((iMax, x, i, arr) => x > arr[iMax] ? i : iMax, 0);
            let bigCon=cv.contourArea(contours.get(indexOfMaxValue))
            let color = new cv.Scalar(255,0,0,255);
            cv.drawContours(src, contours, indexOfMaxValue, color, 3, cv.LINE_8, hierarchy, 100);
            console.log(bigCon);
            cv.imshow('canvasOutput', src);

        }

        const uploadFiles = async (imgClass) => {

            const classimg=imgClass.replace(/ /g,'').toLowerCase();            
            const fileName=inputElement.files[0].name;
            const name=classimg+"_"+Math.floor((Math.random() * 10000000000) + 1)+"_"+fileName;

            const blobOptions = {
                blobHTTPHeaders: { blobContentType: 'image/jpeg'},
            };
            try {
                console.log("Uploading files...");
                const promises = [];

                const blockBlobURL = azblob.BlockBlobURL.fromContainerURL(containerURL, name);
                promises.push(azblob.uploadBrowserDataToBlockBlob(azblob.Aborter.none, inputElement.files[0], blockBlobURL,blobOptions));

                await Promise.all(promises);
                console.log("Done.");
                apiCall(name);
                
            } catch (error) {
                console.log(error);
            }
        }

        const apiCall = (file) => {

            let data = {fileName: file};

            fetch("http://localhost:5000/", {
                headers: {
                'Content-Type': 'application/json'
                },    
                method: "POST", 
                body: JSON.stringify(data)
            }).then(response => response.json())
            .then(result => {
                $.each(result,function(key,value){
                    $('#ocr').append("<H4>"+key +":- "+value+"</H4>")
                });
                console.log('Success:', result);
            })
            .catch(error => {
            console.error('Error:', error);
            });

        }

        const faceDetect=()=>{
            let src = cv.imread(imgElement);
            let gray = new cv.Mat();
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
            let faces = new cv.RectVector();
            let eyes = new cv.RectVector();
            let faceCascade = new cv.CascadeClassifier();
            // load pre-trained classifiers
            faceCascade.load('haarcascade_frontalface_default.xml');
            // detect faces
            let msize = new cv.Size(0, 0);

            // try to change scaleFactor  and minNeighbors values
            faceCascade.detectMultiScale(gray, faces,1.05,0);
            for (let i = 0; i < faces.size(); ++i) {
                let roiGray = gray.roi(faces.get(i));
                let roiSrc = src.roi(faces.get(i));
                let point1 = new cv.Point(faces.get(i).x, faces.get(i).y);
                let point2 = new cv.Point(faces.get(i).x + faces.get(i).width,
                                        faces.get(i).y + faces.get(i).height);
                cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
                roiGray.delete(); roiSrc.delete();
            }
            cv.imshow('canvasOutput', src);
            src.delete(); gray.delete(); faceCascade.delete();
            faces.delete(); eyes.delete();
        }


    </script>
    <script async src="js/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>

</html>